{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"../../logo.png\" alt=\"Header\" style=\"width: 800px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "@Copyright (C): 2010-2022, Shenzhen Yahboom Tech  \n",
    "@Author: Liusen  \n",
    "@Date: 2020-03-18 17:42:02  \n",
    "@LastEditors: Liusen  \n",
    "@LastEditTime: 2020-03-18 17:42:02   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train svm model and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn import svm\n",
    "from sklearn.externals import joblib\n",
    " \n",
    "# Get all .png files in the specified path\n",
    "def get_file_list(path):\n",
    "    return [os.path.join(path, f) for f in os.listdir(path) if f.endswith(\".png\")]\n",
    " \n",
    "# Parse the name of the .png image file\n",
    "def get_img_name_str(imgPath):\n",
    "    return imgPath.split(os.path.sep)[-1]\n",
    " \n",
    " \n",
    "# Convert 28px*28px image data to 1*784 numpy vector\n",
    "# Convert 28px*28px image data to 1*784 numpy vector\n",
    "# Parameters: imgFile--image name such as: 1.png\n",
    "# Return: 1*784 numpy vector\n",
    "def img2vector(imgFile):\n",
    "    # print(\"in img2vector func--para:{}\".format(imgFile))\n",
    "    img = Image.open(imgFile).convert('L')\n",
    "    img_arr = np.array(img, 'i')  # 28px * 28px grayscale image\n",
    "    img_normalization = np.round(img_arr / 255)  # Normalize the gray value\n",
    "    img_arr2 = np.reshape(img_normalization, (1, -1))  # 1 * 784 matrix\n",
    "    return img_arr2\n",
    " \n",
    "# Read all data in a category and convert it into a matrix\n",
    "# Parameters:\n",
    "#    basePath:The basic path where the image data is located\n",
    "#       MNIST-data/train/\n",
    "#       MNIST-data/test/\n",
    "#    cla：classification name\n",
    "#       0,1,2,...,9\n",
    "# Returns: all data of a certain category-[number of samples * (image width x image height)] matrix\n",
    "def read_and_convert(imgFileList):\n",
    "    dataLabel = []  # Storage class label\n",
    "    dataNum = len(imgFileList)\n",
    "    dataMat = np.zeros((dataNum, 784))  # dataNum*784 matrix\n",
    "    for i in range(dataNum):\n",
    "        imgNameStr = imgFileList[i]\n",
    "        imgName = get_img_name_str(imgNameStr)  # Get the number of the current number.png\n",
    "        # print(\"imgName: {}\".format(imgName))\n",
    "        classTag = imgNameStr.split(os.path.sep)[-2]\n",
    "        # classTag = imgName.split(\".\")[0].split(\"_\")[0]  #Get class label (number)\n",
    "        #print(classTag)\n",
    "        #print(imgNameStr)\n",
    "        dataLabel.append(classTag)\n",
    "        dataMat[i, :] = img2vector(imgNameStr)\n",
    "    return dataMat, dataLabel\n",
    "  \n",
    "# Read training data\n",
    "def read_all_data():\n",
    "    cName = ['1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "    #path = sys.path[1]\n",
    "    train_data_path = 'MNIST_data/train/0' # os.path.join(path, './MNIST_data/train/0')\n",
    "    print(train_data_path)\n",
    "    #train_data_path = \"./MNIST_data/train/0\"\n",
    "    print('0')\n",
    "    flist = get_file_list(train_data_path)\n",
    "    #print(flist)\n",
    "    dataMat, dataLabel = read_and_convert(flist)\n",
    "    for c in cName:\n",
    "        print(c)\n",
    "        #train_data_path = os.path.join(path, './MNIST_data/train/') + c\n",
    "        train_data_path = 'MNIST_data/train/' + c\n",
    "        flist_ = get_file_list(train_data_path)\n",
    "        dataMat_, dataLabel_ = read_and_convert(flist_)\n",
    "        dataMat = np.concatenate((dataMat, dataMat_), axis=0)\n",
    "        dataLabel = np.concatenate((dataLabel, dataLabel_), axis=0)\n",
    "    # print(dataMat.shape)\n",
    "    # print(len(dataLabel))\n",
    "    return dataMat, dataLabel\n",
    " \n",
    "'''\n",
    "SVC parameter\n",
    "svm.SVC(C=1.0,kernel='rbf',degree=3,gamma='auto',coef0=0.0,shrinking=True,probability=False,\n",
    "tol=0.001,cache_size=200,class_weight=None,verbose=False,max_iter=-1,decision_function_shape='ovr',random_state=None)\n",
    "\n",
    "C：C-SVC penalty parameter C, the default value is 1.0\n",
    "The larger C is, the equivalent of punishing the slack variable. It is hoped that the slack variable will be close to 0, that is, the penalty for misclassification will increase, which tends to fully split the training set.\n",
    "The accuracy is high, but the generalization ability is weak. C value is small, the penalty for misclassification is reduced, fault tolerance is allowed, they are regarded as noise points, and the generalization ability is strong.\n",
    "\n",
    "kernel:Kernel function, default is rbf, it can be set to‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’ \n",
    "    0 – linear：u'v\n",
    " 　 1 – Polynomial：(gamma*u'*v + coef0)^degree\n",
    "  　2 – RBF function：exp(-gamma|u-v|^2)\n",
    "  　3 –sigmoid：tanh(gamma*u'*v + coef0)\n",
    "\n",
    "\n",
    "degree: The dimension of the polynomial poly function, which is 3 by default. It will be ignored when other kernel functions are selected. (Useless)\n",
    "\n",
    "gamma: Kernel function parameters of ‘rbf’, ‘poly’ and ‘sigmoid’. The default is ‘auto’, then 1/n_features will be selected\n",
    "\n",
    "coef0: constant term of the kernel function. Useful for ‘poly’ and ‘sigmoid’. (Useless)\n",
    "\n",
    "probability: whether to use probability estimation, the default is False\n",
    "\n",
    "shrinking: Whether to use shrinking heuristic method, the default is true\n",
    "\n",
    "tol: the size of the error value for stopping training, the default is 1e-3\n",
    "\n",
    "cache_size: The cache size of the core function cache, the default is 200\n",
    "\n",
    "class_weight: The weight of the category, passed in the form of a dictionary. Set the parameter C of the first category to weight *C (C in C-SVC)\n",
    "\n",
    "verbose: Allow redundant output.\n",
    "\n",
    "max_iter: Maximum number of iterations. -1 is unlimited.\n",
    "\n",
    "decision_function_shape: ‘ovo’, ‘ovr’ or None, default = None3 (select ovr, one-to-many)\n",
    "\n",
    "random_state: seed value, int value when the data is shuffled\n",
    "The main adjustment parameters are: C, kernel, degree, gamma, coef0\n",
    "''' \n",
    "# Create a model\n",
    "def create_svm(dataMat, dataLabel,path,decision='ovr'):\n",
    "    clf = svm.SVC(C=1.0,kernel='rbf',decision_function_shape=decision)\n",
    "    rf =clf.fit(dataMat, dataLabel)\n",
    "    joblib.dump(rf, path)\n",
    "    return clf\n",
    "\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    # clf = svm.SVC(decision_function_shape='ovr')\n",
    "    st = time.clock()\n",
    "    dataMat, dataLabel = read_all_data()\n",
    "    #path = sys.path[1]\n",
    "    #model_path=os.path.join(path,'model\\\\svm.model')\n",
    "    model_path = 'model/svm.model'\n",
    "    create_svm(dataMat, dataLabel, model_path, decision='ovr')\n",
    "    et = time.clock()\n",
    "    print(\"Training spent {:.4f}s.\".format((et - st)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
