{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"../../logo.png\" alt=\"Header\" style=\"width: 800px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "@Copyright (C): 2010-2022, Shenzhen Yahboom Tech  \n",
    "@Author: Liusen  \n",
    "@Date: 2020-03-16 18:02:02  \n",
    "@LastEditors: Liusen  \n",
    "@LastEditTime: 2020-03-16 18:02:02    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Seven-layer convolutional neural network using LeNet5 for MNIST handwritten digit recognition\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# Read training data into mnist variable\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)\n",
    "\n",
    "# Create nodes for input images and target output categories\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784]) #  Data required for training  Placeholder\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10]) # Label data required for training  Placeholder\n",
    "\n",
    "# *********** Construct a multi-layer convolutional network *************** #\n",
    "\n",
    "#  Initialize weights, offsets, convolutions, and pooling operations to avoid repeated initialization operations when building models\n",
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1) # 取随机值，符合均值为0，标准差stddev为0.1\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "# The first parameter of # x is the number of pictures, the second and third parameters are the height and width of the picture, \n",
    "# and the fourth parameter is the number of picture channels.\n",
    "# W The first two parameters are the size of the convolution kernel, the third parameter is the number of image channels, \n",
    "# and the fourth parameter is the number of convolution kernels\n",
    "# strides is the convolution step size, the first and fourth parameters must be 1, \n",
    "# because the step size of the convolution layer is only valid for the length and width of the matrix\n",
    "# padding indicates the form of convolution, that is, whether to consider the boundary. \"SAME\" is to consider the boundary,\n",
    "# when there is not enough to fill the surrounding with 0,\"VALID\" is not considered\n",
    "\n",
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "#  x The format of the parameter is the same as the x format in tf.nn.conv2d, ksize is the scale of the pooling layer filter, and strides is the filter step size\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "# Change x to a 4-dimensional tensor, the first dimension represents the number of samples, the second and third dimensions represent the image length and width, \n",
    "# and the fourth dimension represents the number of image channels\n",
    "x_image = tf.reshape(x, [-1,28,28,1]) # -1 means any number of samples, the size is 28x28, and tensor with depth is 1 \n",
    "\n",
    "# First layer:convolution \n",
    "W_conv1 = weight_variable([5, 5, 1, 32]) # Convolution calculates 32 features in each 5x5 patch.\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1) \n",
    "\n",
    "# Second layer: Pooling\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "# Third layer: convolution \n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "\n",
    "# Fourth layer: Pooling\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "# Fifth layer: Fully connected layer\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "# Add dropout before the output layer to reduce overfitting\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "# Sixth layer: Fully connected layer\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "# Seventh layer: output layer\n",
    "y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "# *************** Train and evaluate models *************** #\n",
    "\n",
    "# Use backpropagation, use the optimizer to minimize the loss function\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))\n",
    "\n",
    "# Check whether our prediction matches the real label (the same index position means matching)\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "#Check whether our prediction matches the real label (the same index position means matching)\n",
    "# tf.argmax(y_conv,dimension), the subscript that returns the largest value is usually used with tf.equal () to calculate the model accuracy\n",
    "# dimension=0 Find by column  dimension=1 Find by row\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))  \n",
    "\n",
    "# Statistical test accuracy, convert the boolean value of correct_prediction to a floating point number to represent right and wrong, and take the average value.\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "saver = tf.train.Saver() # Define saver\n",
    "\n",
    "# *************** Start training  *************** #\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for i in range(1000):\n",
    "      batch = mnist.train.next_batch(50)\n",
    "      if i%50 == 0:\n",
    "        # Assess the accuracy of the model, Dropout is not used at this stage\n",
    "        train_accuracy = accuracy.eval(feed_dict={x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "\n",
    "      # Train the model, use 50% Dropout at this stage\n",
    "      train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5}) \n",
    "\n",
    "    saver.save(sess, './model/model.ckpt') # Model storage location\n",
    "\n",
    "    print(\"test accuracy %g\"%accuracy.eval(feed_dict={x: mnist.test.images [0:2000], y_: mnist.test.labels [0:2000], keep_prob: 1.0}))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten digital image preprocessing MNIST requires data to be 28 * 28 pixels, single channel, and requires binarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# This code is a processing method when the picture is not black and white or the picture size is not 28 * 28. \n",
    "# The picture below is directly a number manually written in the drawing software 28 * 28\n",
    "import cv2\n",
    "cut_img = cv2.imread(\"./images/4.png\", 1)\n",
    "resize_img = cv2.resize(cut_img, (28,28)) # 调整图像尺寸为28*28\n",
    "ret, thresh_img = cv2.threshold(resize_img,127,255,cv2.THRESH_BINARY) # 二值\n",
    "cv2.imwrite('./images/4_1.png', thresh_img)  # 预处理后图像保存位置\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten digit recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "im = Image.open('./images/3.png')\n",
    "data = list(im.getdata())\n",
    "\n",
    "result = [(255-x[0])*1.0/255.0 for x in data] \n",
    "print(result)\n",
    "\n",
    "\n",
    "# Create nodes for input images and target output categories\n",
    "x = tf.placeholder(\"float\", shape=[None, 784]) # Data required for training Placeholder\n",
    "\n",
    "# *************** Construct a multi-layer convolutional network *************** #\n",
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1) #Take a random value, the mean is 0, and the standard deviation stddev is 0.1\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "x_image = tf.reshape(x, [-1,28,28,1]) # -1 means any number of samples, the size is 28x28, and tensor with depth is 1 \n",
    "\n",
    "W_conv1 = weight_variable([5, 5, 1, 32]) # Convolution calculates 32 features in each 5x5 patch.\n",
    "b_conv1 = bias_variable([32])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1) \n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "# Add dropout before the output layer to reduce overfitting\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "# Fully connected layer\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "# Output layer\n",
    "# tf.nn.softmax()Turn the output layer of the neural network into a probability \n",
    "y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "saver = tf.train.Saver() # Define saver\n",
    "\n",
    "# *************** Start recognize *************** #\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver.restore(sess, \"./model/model.ckpt\")#The previously saved model parameters are used here\n",
    "\n",
    "prediction = tf.argmax(y_conv,1)\n",
    "predint = prediction.eval(feed_dict={x: [result],keep_prob: 1.0}, session=sess)\n",
    "\n",
    "print(\"recognize result: %d\" %predint[0])\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
